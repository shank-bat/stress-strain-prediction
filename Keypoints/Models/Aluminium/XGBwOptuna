import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import r2_score
from xgboost import XGBRegressor
from sklearn.multioutput import MultiOutputRegressor
import optuna

# -----------------------------
# Load data
# -----------------------------
df = pd.read_csv("/home/shu/projects/stress-strain-prediction/Keypoints/Databases/al_data_cleaned.csv")

X = df.drop(columns=["Elongation (%)", "Tensile Strength (MPa)", "Yield Strength (MPa)", "class"])
y = df[["Elongation (%)", "Tensile Strength (MPa)", "Yield Strength (MPa)"]]

categorical = ["Processing"]
numeric = [col for col in X.columns if col not in categorical]

preprocessor = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), numeric),
        ("cat", OneHotEncoder(handle_unknown="ignore"), categorical),
    ]
)

# -----------------------------
# Objective function for Optuna
# -----------------------------
def objective(trial):
    params = {
        "n_estimators": trial.suggest_int("n_estimators", 200, 1000),
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3, log=True),
        "max_depth": trial.suggest_int("max_depth", 3, 10),
        "subsample": trial.suggest_float("subsample", 0.6, 1.0),
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.6, 1.0),
        "gamma": trial.suggest_float("gamma", 0, 5),
        "reg_lambda": trial.suggest_float("reg_lambda", 1e-3, 10, log=True),
        "reg_alpha": trial.suggest_float("reg_alpha", 1e-3, 10, log=True),
        "random_state": 42,
        "tree_method": "hist",   # <-- use hist
        "device": "cuda"         # <-- send training to GPU
    }


    xgb = MultiOutputRegressor(XGBRegressor(**params))
    pipeline = Pipeline(steps=[
        ("preprocessor", preprocessor),
        ("regressor", xgb)
    ])

    # Cross-validation
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    r2_scores = []

    for train_idx, test_idx in kf.split(X):
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
        
        pipeline.fit(X_train, y_train)
        y_pred = pipeline.predict(X_test)
        
        # mean R² across outputs
        r2_scores.append(r2_score(y_test, y_pred, multioutput="uniform_average"))
    
    return np.mean(r2_scores)

# -----------------------------
# Run Optuna study
# -----------------------------
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=50)  # increase trials if you want deeper search

print("\nBest trial:")
print("  Value (mean CV R²):", study.best_trial.value)
print("  Params:", study.best_trial.params)
